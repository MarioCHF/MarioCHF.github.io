---
title: "Transformer reimplementation"
excerpt: "An implementation of the original transformer arquitecture. <br/><img src='/images/transformerAttAllUNeed.png'>"
collection: portfolio
---

Implementation from scratch of the module introduced in the well-known paper "Attention is All You Need", transformers. Among the implemented components, 
multi-head attention, positional encoding, and the decoder stand out. Once defined, the classes are used to build and train 2 transformers;
 one for sentiment analysis using the IMDB dataset and one for audio prediction using the SHD dataset. [Full code](https://github.com/MarioCHF/TransformerEncoderDecoder) is available in my GitHub repo. An in depth 
 explanation of the code can be read [here](https://mariochf.github.io/files/TransformerReimplementation.pdf). 

<br/><img src='/images/transformerAttAllUNeed.png'>